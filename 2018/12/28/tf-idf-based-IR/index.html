<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>基于TF-IDF的文本检索实践 | Sakya Personal Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="基本问题设定 1.给定一批query和doc库(doc库中包括两类信息：文本和对应的url，以”\t”作为分隔符，doc之间分隔符为换行符) 2.利用tf-idf score为每一个query找到最相关的topN个doc 开发环境：python2.7 with jieba">
<meta name="keywords" content="practice">
<meta property="og:type" content="article">
<meta property="og:title" content="基于TF-IDF的文本检索实践">
<meta property="og:url" content="http://yoursite.com/2018/12/28/tf-idf-based-IR/index.html">
<meta property="og:site_name" content="Sakya Personal Blog">
<meta property="og:description" content="基本问题设定 1.给定一批query和doc库(doc库中包括两类信息：文本和对应的url，以”\t”作为分隔符，doc之间分隔符为换行符) 2.利用tf-idf score为每一个query找到最相关的topN个doc 开发环境：python2.7 with jieba">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-12-29T03:21:21.871Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基于TF-IDF的文本检索实践">
<meta name="twitter:description" content="基本问题设定 1.给定一批query和doc库(doc库中包括两类信息：文本和对应的url，以”\t”作为分隔符，doc之间分隔符为换行符) 2.利用tf-idf score为每一个query找到最相关的topN个doc 开发环境：python2.7 with jieba">
  
    <link rel="alternate" href="/atom.xml" title="Sakya Personal Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Sakya Personal Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-tf-idf-based-IR" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/28/tf-idf-based-IR/" class="article-date">
  <time datetime="2018-12-28T04:40:50.000Z" itemprop="datePublished">2018-12-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      基于TF-IDF的文本检索实践
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="基本问题设定"><a href="#基本问题设定" class="headerlink" title="基本问题设定"></a>基本问题设定</h1><ul>
<li>1.给定一批query和doc库(doc库中包括两类信息：文本和对应的url，以”\t”作为分隔符，doc之间分隔符为换行符)</li>
<li>2.利用tf-idf score为每一个query找到最相关的topN个doc</li>
<li>开发环境：python2.7 with jieba</li>
</ul>
<a id="more"></a>
<p>首先处理doc库，在处理过程中生成doc库的词表，term的idf表，doc_id到doc映射(为了减少内存)，term到doc的倒排索引</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def generate_vocab_inverted_index(filename):</span><br><span class="line">    vocab = set()</span><br><span class="line">    vocab_idf = dict()</span><br><span class="line">    id2title = dict()</span><br><span class="line">    term2ids = dict()</span><br><span class="line">    docNum = 0</span><br><span class="line">    f = open(filename, &apos;r&apos;)</span><br><span class="line">    for line in f.xreadlines():</span><br><span class="line">        if line.strip() and len(line.strip().split(&apos;\t&apos;)) == 2:</span><br><span class="line">            docNum += 1</span><br><span class="line">            title = line.strip().split(&apos;\t&apos;)[0].decode(&apos;utf-8&apos;)</span><br><span class="line">            #title = line.strip().decode(&apos;utf-8&apos;)</span><br><span class="line">            id2title[docNum] = line.strip().decode(&apos;utf-8&apos;)</span><br><span class="line">            term_split = set(jieba.lcut(title))</span><br><span class="line">            for term in term_split:</span><br><span class="line">                vocab.add(term)</span><br><span class="line">                vocab_idf[term] = vocab_idf.get(term,0) + 1</span><br><span class="line">                if term in term2ids:</span><br><span class="line">                    term2ids[term].append(docNum)</span><br><span class="line">                else:</span><br><span class="line">                    term2ids[term] = [docNum]</span><br><span class="line">    f.close()</span><br><span class="line">    print &quot;vocabulary size is:%d&quot; % len(vocab)</span><br><span class="line">    for term,n in vocab_idf.iteritems():</span><br><span class="line">        if n &gt; 0:</span><br><span class="line">            vocab_idf[term] = 1.0 + math.log(float(docNum) / n)</span><br><span class="line">        else:</span><br><span class="line">            vocab_idf[term] = 1.0</span><br><span class="line">    return vocab,vocab_idf,id2title,term2ids</span><br></pre></td></tr></table></figure>
<p>计算tf函数，考虑到文本长度，需要做normalize</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def termFrequency(term, document):</span><br><span class="line">    normalizeDocument = jieba.lcut(document)</span><br><span class="line">    return normalizeDocument.count(term) / float(len(normalizeDocument))</span><br></pre></td></tr></table></figure>
<p>计算doc中所有doc里面每个term的tf-idf score</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def calculate_title_score(vocab_idf,filename):</span><br><span class="line">    title2score = dict()</span><br><span class="line">    num = 0</span><br><span class="line">    f = open(filename,&apos;r&apos;)</span><br><span class="line">    for line in f.xreadlines():</span><br><span class="line">        if line.strip() and len(line.strip().split(&apos;\t&apos;)) == 2:</span><br><span class="line">            num += 1</span><br><span class="line">            line = line.strip().split(&apos;\t&apos;)[0].decode(&apos;utf-8&apos;)</span><br><span class="line">            title2score[num] = dict()</span><br><span class="line">            term_split = set(jieba.lcut(line))</span><br><span class="line">            for term in term_split:</span><br><span class="line">                tf = termFrequency(term, line)</span><br><span class="line">                if term in vocab_idf:</span><br><span class="line">                    idf = vocab_idf[term]</span><br><span class="line">                    title2score[num][term] = tf * idf</span><br><span class="line">            </span><br><span class="line">    f.close()</span><br><span class="line">    print &quot;%s----%d titles score are computed&quot; % (time.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;),num)</span><br><span class="line">    return title2score</span><br></pre></td></tr></table></figure>
<p>保存vocabulary的idf表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def dump_vocab_idf(idf_dict,filename):</span><br><span class="line">    sort_idf = sorted(idf_dict.items(), key=lambda x: x[1])</span><br><span class="line">    f = open(filename,&quot;w&quot;)</span><br><span class="line">    for item in sort_idf:</span><br><span class="line">        f.write(&quot;%s\t%.6f\n&quot; %(item[0].encode(&quot;utf-8&quot;),item[1]))</span><br><span class="line">    f.close()</span><br><span class="line">    print &quot;IDF score of vocabulary is all dumped into %s&quot; % filename</span><br></pre></td></tr></table></figure></p>
<p>主函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    print &quot;%s----Process start.......&quot; % time.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;)</span><br><span class="line">    query_file = &quot;query.txt&quot;</span><br><span class="line">    title_file = &quot;doc.txt&quot;</span><br><span class="line">    vocab,vocab_idf,id2title,term2ids = generate_vocab_inverted_index(title_file)</span><br><span class="line">    idf_file = &quot;qa_repo_idf.txt&quot;</span><br><span class="line">    dump_vocab_idf(vocab_idf,idf_file)</span><br><span class="line">    </span><br><span class="line">    title_term_tf_idf = calculate_title_score(vocab_idf,title_file) # key:title value:&#123;word:tf,idf&#125;+</span><br><span class="line">    retrieval_result = &quot;retrieval_result.txt&quot;</span><br><span class="line">    retrieval_no_result = &quot;no_result_query.txt&quot;</span><br><span class="line">    topN = 5</span><br><span class="line">    f = open(query_file,&apos;r&apos;)</span><br><span class="line">    fo = open(retrieval_result,&apos;w&apos;)</span><br><span class="line">    fo_no = open(retrieval_no_result,&apos;w&apos;)</span><br><span class="line">    query_post_num = 0</span><br><span class="line">    for line in f.xreadlines():</span><br><span class="line">        if line.strip():</span><br><span class="line">            query_post_num += 1</span><br><span class="line">            match_score = dict()</span><br><span class="line">            query = line.strip().decode(&apos;utf-8&apos;)</span><br><span class="line">            query_norm = 0.0</span><br><span class="line">            query_max_idf = 0.0</span><br><span class="line">            max_term = &quot;&quot;</span><br><span class="line">            query_split = set(jieba.lcut(query))</span><br><span class="line">            for term in query_split:</span><br><span class="line">                tf = termFrequency(term, query)</span><br><span class="line">                if term in vocab_idf:</span><br><span class="line">                    idf = vocab_idf[term]</span><br><span class="line">                    query_norm += pow(tf*idf,2)</span><br><span class="line">                    if idf &gt; query_max_idf:</span><br><span class="line">                        max_term = term</span><br><span class="line">            query_norm = math.sqrt(query_norm)</span><br><span class="line">            if not max_term in term2ids:</span><br><span class="line">                continue </span><br><span class="line">            candidates = term2ids[max_term]</span><br><span class="line">            </span><br><span class="line">            for title_id in candidates:                </span><br><span class="line">                inter_term = query_split &amp; set(jieba.lcut(id2title[title_id].split(&apos;\t&apos;)[0]))</span><br><span class="line">                if len(inter_term) &lt; 1:</span><br><span class="line">                    continue</span><br><span class="line">                # consine similarity between query &amp; title</span><br><span class="line">                numerator = 0.0</span><br><span class="line">                for term in inter_term:</span><br><span class="line">                    # print &quot;inter term:&quot; + term</span><br><span class="line">                    tf = termFrequency(term, query)</span><br><span class="line">                    if term in vocab_idf:</span><br><span class="line">                        idf = vocab_idf[term]</span><br><span class="line">                        numerator += tf*idf * title_term_tf_idf[title_id][term]</span><br><span class="line">                </span><br><span class="line">                title_norm = 0.0</span><br><span class="line">                for term,score in title_term_tf_idf[title_id].iteritems():</span><br><span class="line">                    title_norm += pow(score,2)</span><br><span class="line">                title_norm = math.sqrt(title_norm)</span><br><span class="line"></span><br><span class="line">                if query_norm * title_norm &gt; 0.0:</span><br><span class="line">                    match_score[title_id] = numerator / (query_norm * title_norm)</span><br><span class="line">            if len(match_score) &lt; topN:</span><br><span class="line">                # print &quot;No enough result for query:%s&quot; % query</span><br><span class="line">                fo_no.write(&quot;%s\n&quot; % query.encode(&apos;utf-8&apos;))</span><br><span class="line">                continue</span><br><span class="line">            sorted_match = sorted(match_score.items(), key = lambda x:x[1], reverse=True)</span><br><span class="line">            for i in range(topN):</span><br><span class="line">                fo.write(&quot;%s\t%s\t%.6f\n&quot; % (query.encode(&apos;utf-8&apos;),id2title[sorted_match[i][0]].encode(&apos;utf-8&apos;),sorted_match[i][1]))</span><br><span class="line">            </span><br><span class="line">            if query_post_num % 1000 == 0:</span><br><span class="line">                print &quot;%s---%d queries have been processed!&quot; % (time.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;),query_post_num)</span><br><span class="line">    f.close()</span><br><span class="line">    fo.close()</span><br><span class="line">    fo_no.close()</span><br><span class="line">    print &quot;All %d queries has been processed!&quot; % query_post_num</span><br></pre></td></tr></table></figure>
<h1 id="Reference-and-Good-Blog-about-TF-IDF"><a href="#Reference-and-Good-Blog-about-TF-IDF" class="headerlink" title="Reference and Good Blog about TF-IDF"></a>Reference and Good Blog about TF-IDF</h1><p><a href="https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/" target="_blank" rel="noopener">Tf-Idf and Cosine similarity</a><br><a href="https://my.oschina.net/stanleysun/blog/1617727" target="_blank" rel="noopener">搜索中的权重度量利器: TF-IDF和BM25</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/28/tf-idf-based-IR/" data-id="cjtznebk2000ci9ajycb5k041" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/practice/">practice</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/01/15/doc-classification-review/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          文本分类算法总结
        
      </div>
    </a>
  
  
    <a href="/2018/12/04/nlp-metrics/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">NLP任务中常用的评价指标汇总</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/code/">code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paper/">paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/practice/">practice</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/share/">share</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/code/" style="font-size: 10px;">code</a> <a href="/tags/paper/" style="font-size: 15px;">paper</a> <a href="/tags/practice/" style="font-size: 20px;">practice</a> <a href="/tags/share/" style="font-size: 15px;">share</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/03/18/linux-hints/">linux开发备忘</a>
          </li>
        
          <li>
            <a href="/2019/02/26/python-hints/">python开发备忘</a>
          </li>
        
          <li>
            <a href="/2019/01/15/text-processing/">中文文本数据处理</a>
          </li>
        
          <li>
            <a href="/2019/01/15/doc-classification-review/">文本分类算法总结</a>
          </li>
        
          <li>
            <a href="/2018/12/28/tf-idf-based-IR/">基于TF-IDF的文本检索实践</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!--script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>